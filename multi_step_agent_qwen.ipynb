{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Step Agent with Qwen/Qwen3-4B-Instruct-2507\n",
                "\n",
                "This notebook implements a multi-step agent using the **Qwen/Qwen3-4B-Instruct-2507** model.\n",
                "It supports:\n",
                "- **Tool Calling**: Arithmetic, Stock/Crypto Prices (yfinance), News Search (Tavily).\n",
                "- **Contextual History**: Maintains conversation history for follow-up queries.\n",
                "- **Gradio UI**: Interactive chat interface.\n",
                "\n",
                "**Note**: This model requires the latest version of `transformers`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "2c308b5c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
                        "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
                        "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
                    ]
                }
            ],
            "source": [
                "# Install latest transformers from source to support Qwen3\n",
                "!pip install -q git+https://github.com/huggingface/transformers.git accelerate yfinance tavily-python gradio"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "80314b10",
            "metadata": {},
            "source": [
                "## 2. Configuration & Model Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2f960c3a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading Qwen/Qwen3-4B-Instruct-2507...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
                        "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
                        "You are not authenticated with the Hugging Face Hub in this notebook.\n",
                        "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "15e47996a3fb4a47a3dd5817a7bbf07a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
                        "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from getpass import getpass\n",
                "import torch\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "\n",
                "# --- API Keys ---\n",
                "try:\n",
                "    from google.colab import userdata\n",
                "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
                "    TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
                "except:\n",
                "    HF_TOKEN = os.getenv('HF_TOKEN')\n",
                "    TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
                "\n",
                "if not HF_TOKEN:\n",
                "    HF_TOKEN = getpass(\"Enter your Hugging Face Token (HF_TOKEN): \")\n",
                "if not TAVILY_API_KEY:\n",
                "    TAVILY_API_KEY = getpass(\"Enter your Tavily API Key (TAVILY_API_KEY): \")\n",
                "\n",
                "os.environ['HF_TOKEN'] = HF_TOKEN\n",
                "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
                "\n",
                "# --- Model Loading ---\n",
                "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
                "print(f\"Loading {MODEL_NAME}...\")\n",
                "\n",
                "# Auto-detect device\n",
                "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "TORCH_DTYPE = \"auto\" if DEVICE == \"cuda\" else torch.float32\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN, trust_remote_code=True)\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    torch_dtype=TORCH_DTYPE,\n",
                "    device_map=\"auto\",\n",
                "    token=HF_TOKEN,\n",
                "    trust_remote_code=True\n",
                ")\n",
                "\n",
                "def generate_response(messages, tools=None):\n",
                "    \"\"\"Generate response from the model, optionally with tools.\"\"\"\n",
                "    # Apply chat template. Qwen models usually handle 'tools' in apply_chat_template if customized,\n",
                "    # but we will manual inject system prompt for robustness if needed, \n",
                "    # HOWEVER, using the standard 'tools' parameter is the 'right way' (Ä‘Ãºng format) for newer transformers.\n",
                "    \n",
                "    try:\n",
                "        text = tokenizer.apply_chat_template(\n",
                "            messages,\n",
                "            tools=tools,\n",
                "            tokenize=False,\n",
                "            add_generation_prompt=True\n",
                "        )\n",
                "    except Exception as e:\n",
                "        # fallback\n",
                "        print(f\"Warning: apply_chat_template issue ({e}), falling back.\")\n",
                "        text = tokenizer.apply_chat_template(\n",
                "            messages,\n",
                "            tokenize=False,\n",
                "            add_generation_prompt=True\n",
                "        )\n",
                "\n",
                "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
                "\n",
                "    # Explicitly disable sampling parameters to avoid warnings\n",
                "    generated_ids = model.generate(\n",
                "        **model_inputs,\n",
                "        max_new_tokens=512,\n",
                "        do_sample=False,\n",
                "        temperature=None,\n",
                "        top_p=None,\n",
                "        top_k=None\n",
                "    )\n",
                "    \n",
                "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):]\n",
                "    content = tokenizer.decode(output_ids, skip_special_tokens=False)\n",
                "    return content"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b39f6b80",
            "metadata": {},
            "source": [
                "## 3. Tool Definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "5ba40692",
            "metadata": {},
            "outputs": [],
            "source": [
                "import yfinance as yf\n",
                "import re\n",
                "import json\n",
                "from tavily import TavilyClient\n",
                "\n",
                "# --- Helper Functions ---\n",
                "def resolve_symbol(symbol):\n",
                "    if not symbol: return None\n",
                "    symbol = symbol.strip().upper()\n",
                "    # Basic mappings\n",
                "    MAPPING = {\n",
                "        \"BITCOIN\": \"BTC-USD\", \"BTC\": \"BTC-USD\",\n",
                "        \"ETHEREUM\": \"ETH-USD\", \"ETH\": \"ETH-USD\",\n",
                "        \"NVIDIA\": \"NVDA\", \"GOOGLE\": \"GOOGL\", \"APPLE\": \"AAPL\",\n",
                "        \"AMAZON\": \"AMZN\", \"MICROSOFT\": \"MSFT\", \"TESLA\": \"TSLA\"\n",
                "    }\n",
                "    # Check mapping\n",
                "    if symbol in MAPPING: return MAPPING[symbol]\n",
                "    for k, v in MAPPING.items():\n",
                "        if k in symbol: return v\n",
                "    # If it looks like a ticker (3-5 chars), use it\n",
                "    if re.match(r'^[A-Z]{1,5}$', symbol):\n",
                "        return symbol\n",
                "    # Fallback: Try with yfinance search (mocked here for speed, or basic heuristics)\n",
                "    return symbol\n",
                "\n",
                "# --- Tools Implementations ---\n",
                "def arithmetic_tool(op, a, b):\n",
                "    try:\n",
                "        a, b = float(a), float(b)\n",
                "        if op == 'add': return a + b\n",
                "        if op == 'subtract': return a - b\n",
                "        if op == 'multiply': return a * b\n",
                "        if op == 'divide': return a / b if b != 0 else \"Error: Div0\"\n",
                "    except: return \"Error: Invalid numbers\"\n",
                "    return \"Error: Unknown Op\"\n",
                "\n",
                "def get_price(symbol):\n",
                "    resolved = resolve_symbol(symbol)\n",
                "    try:\n",
                "        ticker = yf.Ticker(resolved)\n",
                "        # fast_info is often faster/more reliable than history for current price\n",
                "        price = ticker.fast_info.last_price\n",
                "        if price:\n",
                "            return price\n",
                "        # Fallback to history\n",
                "        hist = ticker.history(period=\"1d\")\n",
                "        if not hist.empty:\n",
                "            return hist['Close'].iloc[-1]\n",
                "        return f\"No price found for {resolved}\"\n",
                "    except Exception as e:\n",
                "        return f\"Error fetching price for {symbol}: {e}\"\n",
                "\n",
                "def get_news(query):\n",
                "    if not TAVILY_API_KEY:\n",
                "        return \"Error: TAVILY_API_KEY not set.\"\n",
                "    try:\n",
                "        client = TavilyClient(api_key=TAVILY_API_KEY)\n",
                "        response = client.search(query, search_depth=\"basic\", max_results=3)\n",
                "        results = response.get('results', [])\n",
                "        if not results: return \"No news found.\"\n",
                "        return \"\\n\".join([f\"- {r['title']} ({r['url']})\" for r in results])\n",
                "    except Exception as e:\n",
                "        return f\"Error fetching news: {e}\"\n",
                "\n",
                "# --- Tool Schemas (JSON format for Qwen) ---\n",
                "tools = [\n",
                "    {\n",
                "        \"type\": \"function\",\n",
                "        \"function\": {\n",
                "            \"name\": \"arithmetic_tool\",\n",
                "            \"description\": \"Perform basic arithmetic operations (add, subtract, multiply, divide).\",\n",
                "            \"parameters\": {\n",
                "                \"type\": \"object\",\n",
                "                \"properties\": {\n",
                "                    \"op\": {\"type\": \"string\", \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"]},\n",
                "                    \"a\": {\"type\": \"number\"},\n",
                "                    \"b\": {\"type\": \"number\"}\n",
                "                },\n",
                "                \"required\": [\"op\", \"a\", \"b\"]\n",
                "            }\n",
                "        }\n",
                "    },\n",
                "    {\n",
                "        \"type\": \"function\",\n",
                "        \"function\": {\n",
                "            \"name\": \"get_price\",\n",
                "            \"description\": \"Get the current stock or cryptocurrency price for a given symbol (e.g., AAPL, BTC, Nvidia).\",\n",
                "            \"parameters\": {\n",
                "                \"type\": \"object\",\n",
                "                \"properties\": {\n",
                "                    \"symbol\": {\"type\": \"string\", \"description\": \"The ticker symbol or company name.\"}\n",
                "                },\n",
                "                \"required\": [\"symbol\"]\n",
                "            }\n",
                "        }\n",
                "    },\n",
                "    {\n",
                "        \"type\": \"function\",\n",
                "        \"function\": {\n",
                "            \"name\": \"get_news\",\n",
                "            \"description\": \"Search for the latest news about a topic.\",\n",
                "            \"parameters\": {\n",
                "                \"type\": \"object\",\n",
                "                \"properties\": {\n",
                "                    \"query\": {\"type\": \"string\", \"description\": \"The search query.\"}\n",
                "                },\n",
                "                \"required\": [\"query\"]\n",
                "            }\n",
                "        }\n",
                "    }\n",
                "]\n",
                "\n",
                "tool_map = {\n",
                "    \"arithmetic_tool\": arithmetic_tool,\n",
                "    \"get_price\": get_price,\n",
                "    \"get_news\": get_news\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "773c044a",
            "metadata": {},
            "source": [
                "## 4. Agent Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "6d06b536",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import re\n",
                "\n",
                "class QwenAgent:\n",
                "    def __init__(self, tools, tool_map):\n",
                "        self.tools = tools\n",
                "        self.tool_map = tool_map\n",
                "\n",
                "    def parse_tool_calls(self, text):\n",
                "        \"\"\"\n",
                "        Parse tool calls from Qwen instructions.\n",
                "        \"\"\"\n",
                "        calls = []\n",
                "        text = str(text)\n",
                "        \n",
                "        # 1. Try <tool_call> XML-like tags\n",
                "        tool_call_pattern = r\"<tool_call>(.*?)</tool_call>\"\n",
                "        matches = re.findall(tool_call_pattern, text, re.DOTALL)\n",
                "        \n",
                "        for m in matches:\n",
                "            try:\n",
                "                call_data = json.loads(m.strip())\n",
                "                calls.append(call_data)\n",
                "            except Exception as e:\n",
                "                print(f\"Warning: Failed to parse tool call JSON: {e} | Content: {m}\")\n",
                "\n",
                "        if calls:\n",
                "            return calls\n",
                "\n",
                "        # 2. Fallback: Detect standard tool structure\n",
                "        try:\n",
                "            json_pattern = r\"\\{.*?\\}\"\n",
                "            potential_jsons = re.findall(json_pattern, text, re.DOTALL)\n",
                "            for pj in potential_jsons:\n",
                "                try:\n",
                "                    data = json.loads(pj)\n",
                "                    if \"name\" in data and \"arguments\" in data:\n",
                "                        calls.append(data)\n",
                "                except:\n",
                "                    continue\n",
                "        except:\n",
                "            pass\n",
                "        \n",
                "        return calls\n",
                "\n",
                "    def run(self, user_query, history=[], max_steps=5):\n",
                "        \"\"\"\n",
                "        Run the agent with conversation history.\n",
                "        \"\"\"\n",
                "        messages = []\n",
                "        # System prompt\n",
                "        messages.append({\"role\": \"system\", \"content\": \"You are a helpful assistant. You can use tools to answer questions. If you need to use a tool, output the function call inside <tool_call> tags.\"})\n",
                "\n",
                "        # Add history (Gradio type='messages' provides list of dicts)\n",
                "        if history:\n",
                "            messages.extend(history)\n",
                "\n",
                "        # Add current query\n",
                "        messages.append({\"role\": \"user\", \"content\": user_query})\n",
                "\n",
                "        for step in range(max_steps):\n",
                "            print(f\"--- Step {step+1} ---\")\n",
                "            \n",
                "            response_text = generate_response(messages, tools=self.tools)\n",
                "            print(f\"Agent Raw Output: {response_text}\")\n",
                "\n",
                "            tool_calls = self.parse_tool_calls(response_text)\n",
                "            \n",
                "            if not tool_calls:\n",
                "                # Final Answer\n",
                "                final_answer = re.sub(r\"<tool_call>.*?</tool_call>\", \"\", response_text, flags=re.DOTALL).strip()\n",
                "                final_answer = final_answer.replace(\"<|im_end|>\", \"\")\n",
                "                return final_answer\n",
                "\n",
                "            # Execute tools\n",
                "            messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
                "            \n",
                "            for call in tool_calls:\n",
                "                func_name = call.get(\"name\")\n",
                "                args = call.get(\"arguments\")\n",
                "                print(f\"Calling Tool: {func_name} with {args}\")\n",
                "                \n",
                "                if func_name in self.tool_map:\n",
                "                    try:\n",
                "                        result = self.tool_map[func_name](**args)\n",
                "                    except Exception as e:\n",
                "                        result = f\"Error executing {func_name}: {e}\"\n",
                "                else:\n",
                "                    result = f\"Error: Tool {func_name} not found.\"\n",
                "                \n",
                "                print(f\"Tool Result: {result}\")\n",
                "                \n",
                "                messages.append({\n",
                "                    \"role\": \"tool\",\n",
                "                    \"name\": func_name,\n",
                "                    \"content\": str(result)\n",
                "                })\n",
                "        \n",
                "        return \"Maximum steps reached.\"\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Gradio UI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipython-input-2190014597.py:12: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
                        "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
                        "* Running on public URL: https://bc7a321b8f0235c4cb.gradio.live\n",
                        "\n",
                        "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><iframe src=\"https://bc7a321b8f0235c4cb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Step 1 ---\n",
                        "Agent Raw Output: <tool_call>\n",
                        "{\"name\": \"get_price\", \"arguments\": {\"symbol\": \"BTC\"}}\n",
                        "</tool_call><|im_end|>\n",
                        "Calling Tool: get_price with {'symbol': 'BTC'}\n",
                        "Tool Result: 87917.0625\n",
                        "--- Step 2 ---\n",
                        "Agent Raw Output: The current price of Bitcoin (BTC) is $87,917.06.<|im_end|>\n",
                        "--- Step 1 ---\n",
                        "Agent Raw Output: <tool_call>\n",
                        "{\"name\": \"arithmetic_tool\", \"arguments\": {\"op\": \"multiply\", \"a\": 87917.06, \"b\": 2}}\n",
                        "</tool_call><|im_end|>\n",
                        "Calling Tool: arithmetic_tool with {'op': 'multiply', 'a': 87917.06, 'b': 2}\n",
                        "Tool Result: 175834.12\n",
                        "--- Step 2 ---\n",
                        "Agent Raw Output: Multiplying the price of Bitcoin ($87,917.06) by 2 results in $175,834.12.<|im_end|>\n",
                        "Keyboard interruption in main thread... closing server.\n",
                        "Killing tunnel 127.0.0.1:7860 <> https://bc7a321b8f0235c4cb.gradio.live\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": []
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import gradio as gr\n",
                "\n",
                "agent = QwenAgent(tools, tool_map)\n",
                "\n",
                "def chat_interface(message, history):\n",
                "    \"\"\"\n",
                "    Gradio Chat Interface callback.\n",
                "    \"\"\"\n",
                "    response = agent.run(message, history=history)\n",
                "    return response\n",
                "\n",
                "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
                "    gr.Markdown(\"# ðŸ¤– Multi-Step Agent (Qwen3-4B-Instruct)\")\n",
                "    \n",
                "    chat = gr.ChatInterface(\n",
                "        fn=chat_interface,\n",
                "        type=\"messages\", \n",
                "        examples=[\n",
                "            \"What is the price of Bitcoin?\",\n",
                "            \"Multiply that price by 2.\",\n",
                "            \"Search for the latest news about OpenAI.\"\n",
                "        ],\n",
                "    )\n",
                "\n",
                "demo.launch(share=True, debug=True)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
