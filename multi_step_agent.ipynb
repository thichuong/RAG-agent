{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Step Financial & Search Agent\n",
                "\n",
                "This notebook implements a multi-step agent using **LiquidAI/LFM2.5-1.2B-Instruct**.\n",
                "The agent is designed to:\n",
                "1. Perform arithmetic (+, -, *, /).\n",
                "2. Fetch latest crypto and stock prices via `yfinance`.\n",
                "3. Search for latest news via `Tavily`.\n",
                "\n",
                "### Agent Flow:\n",
                "1. **Router**: Analyzes the query and identifies necessary tool calls (JSON output).\n",
                "2. **Executor**: Executes identified tool calls and retrieves results.\n",
                "3. **Synthesizer**: Combines the results into a final cohesive answer."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers torch yfinance tavily-python accelerate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration & Model Loading"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 API Keys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from getpass import getpass\n",
                "\n",
                "# Set API Keys\n",
                "try:\n",
                "    from google.colab import userdata\n",
                "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
                "    TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
                "except:\n",
                "    HF_TOKEN = os.getenv('HF_TOKEN')\n",
                "    TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
                "\n",
                "if not HF_TOKEN:\n",
                "    HF_TOKEN = getpass(\"Enter your Hugging Face Token (HF_TOKEN): \")\n",
                "\n",
                "if not TAVILY_API_KEY:\n",
                "    TAVILY_API_KEY = getpass(\"Enter your Tavily API Key (TAVILY_API_KEY): \")\n",
                "\n",
                "# Export to environment for tools to use if needed\n",
                "os.environ['HF_TOKEN'] = HF_TOKEN\n",
                "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Model Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model LiquidAI/LFM2.5-1.2B-Instruct on cuda...\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import json\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "\n",
                "# Robust Device Configuration\n",
                "if torch.cuda.is_available():\n",
                "    try:\n",
                "        major, minor = torch.cuda.get_device_capability()\n",
                "        if major < 7:\n",
                "            print(f\"GPU Capability {major}.{minor} is too low for current PyTorch. Falling back to CPU.\")\n",
                "            DEVICE = \"cpu\"\n",
                "        else:\n",
                "            DEVICE = \"cuda\"\n",
                "    except:\n",
                "        DEVICE = \"cpu\"\n",
                "else:\n",
                "    DEVICE = \"cpu\"\n",
                "\n",
                "TORCH_DTYPE = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
                "# Switched to Instruct version for more consistent direct outputs\n",
                "MODEL_NAME = \"LiquidAI/LFM2.5-1.2B-Instruct\"\n",
                "\n",
                "print(f\"Loading model {MODEL_NAME} on {DEVICE}...\")\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    torch_dtype=TORCH_DTYPE,\n",
                "    device_map=\"auto\" if DEVICE == \"cuda\" else None,\n",
                "    token=HF_TOKEN\n",
                ")\n",
                "if DEVICE == \"cpu\":\n",
                "    model = model.to(\"cpu\")\n",
                "\n",
                "def generate(prompt, max_new_tokens=500):\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
                "    return tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Tool Definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import yfinance as yf\n",
                "from tavily import TavilyClient\n",
                "\n",
                "def arithmetic_tool(op, a, b):\n",
                "    \"\"\"Performs basic arithmetic operations.\"\"\"\n",
                "    try:\n",
                "        a, b = float(a), float(b)\n",
                "        if op == 'add': return a + b\n",
                "        if op == 'subtract': return a - b\n",
                "        if op == 'multiply': return a * b\n",
                "        if op == 'divide': return a / b if b != 0 else \"Error: Division by zero\"\n",
                "    except Exception as e:\n",
                "        return f\"Arithmetic Error: {e}\"\n",
                "    return \"Invalid operation\"\n",
                "\n",
                "def price_tool(symbol):\n",
                "    \"\"\"Fetches the latest price for a stock or crypto symbol.\"\"\"\n",
                "    try:\n",
                "        # Auto-correct common crypto symbols\n",
                "        crypto_majors = [\"BTC\", \"ETH\", \"SOL\", \"BNB\", \"XRP\", \"ADA\", \"DOGE\"]\n",
                "        if symbol.upper() in crypto_majors:\n",
                "            symbol = f\"{symbol.upper()}-USD\"\n",
                "        \n",
                "        # Auto-correct common stock naming errors\n",
                "        if symbol.upper() == \"NVIDIA\": symbol = \"NVDA\"\n",
                "        if symbol.upper() == \"TESLA\": symbol = \"TSLA\"\n",
                "        if symbol.upper() == \"GOOGLE\": symbol = \"GOOGL\"\n",
                "\n",
                "        ticker = yf.Ticker(symbol)\n",
                "        hist = ticker.history(period=\"1d\")\n",
                "        if not hist.empty:\n",
                "            return float(hist['Close'].iloc[-1])\n",
                "        return f\"Could not find price for {symbol}. Try a specific ticker like NVDA or BTC-USD.\"\n",
                "    except Exception as e:\n",
                "        return f\"Price Error: {e}\"\n",
                "\n",
                "def news_tool(query):\n",
                "    \"\"\"Searches for latest news using Tavily API.\"\"\"\n",
                "    if not TAVILY_API_KEY:\n",
                "        return \"Tavily API Key missing.\"\n",
                "    try:\n",
                "        client = TavilyClient(api_key=TAVILY_API_KEY)\n",
                "        response = client.search(query=query, search_depth=\"basic\")\n",
                "        results = [f\"- {r['title']}: {r['content'][:200]}...\" for r in response.get('results', [])]\n",
                "        return \"\\n\".join(results[:3]) if results else \"No news found.\"\n",
                "    except Exception as e:\n",
                "        return f\"Search Error: {e}\"\n",
                "\n",
                "# Tool mapping\n",
                "TOOLS = {\n",
                "    \"arithmetic\": arithmetic_tool,\n",
                "    \"get_price\": price_tool,\n",
                "    \"get_news\": news_tool\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Agent Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def router_prompt(query):\n",
                "    # Double curly braces {{ }} are used to escape them in f-strings\n",
                "    return f\"\"\"You are a strict AI Workflow Router. \n",
                "Analyze the user query and output a JSON array of tool calls.\n",
                "\n",
                "TOOLS:\n",
                "1. arithmetic(op, a, b): op=['add','subtract','multiply','divide']. \n",
                "   Note: If a value is unknown (like a stock price), do NOT call arithmetic yet.\n",
                "2. get_price(symbol): symbol is stock (NVDA, AAPL) or crypto (BTC-USD, ETH-USD).\n",
                "3. get_news(query): news search string.\n",
                "\n",
                "RULES:\n",
                "- Output ONLY a valid JSON array. \n",
                "- Do NOT include markdown code blocks (```json).\n",
                "- Do NOT include explanations.\n",
                "- Handle multiple tasks simultaneously.\n",
                "- For math involving real-time prices (e.g., \\\"Price of BTC + 500\\\"), ONLY call 'get_price'. The Synthesizer will handle the math.\n",
                "\n",
                "Example Query: \\\"Calculate 1024 times 4 and show BTC price\\\"\n",
                "Example Output: [{{\\\"function\\\": \\\"arithmetic\\\", \\\"args\\\": {{\\\"op\\\": \\\"multiply\\\", \\\"a\\\": 1024, \\\"b\\\": 4}}}}, {{\\\"function\\\": \\\"get_price\\\", \\\"args\\\": {{\\\"symbol\\\": \\\"BTC-USD\\\"}}}}]\n",
                "\n",
                "User Query: {query}\n",
                "JSON:\n",
                "\"\"\"\n",
                "\n",
                "def synthesize_prompt(query, metadata):\n",
                "    return f\"\"\"You are a Financial Research Assistant Assistant.\n",
                "Combine the user query and the retrieved tool results into a clear, professional answer.\n",
                "If the tool results contain a price, and the user asked for math (e.g., + 500), PERFORM that calculation yourself in the final answer.\n",
                "\n",
                "User Query: {query}\n",
                "Tool Results: {json.dumps(metadata, indent=2)}\n",
                "\n",
                "Final Answer:\n",
                "\"\"\"\n",
                "\n",
                "def extract_json(text):\n",
                "    \"\"\"Robustly extracts JSON from potentially messy model output.\"\"\"\n",
                "    t = text.strip()\n",
                "    # Remove logic for <think> tags as Instruct model typically doesn't use them\n",
                "    if \"</think>\" in t:\n",
                "        t = t.split(\"</think>\")[-1].strip()\n",
                "    if t.startswith(\"```json\"):\n",
                "        t = t[7:].strip()\n",
                "    if t.startswith(\"```\"):\n",
                "        t = t[3:].strip()\n",
                "    if t.endswith(\"```\"):\n",
                "        t = t[:-3].strip()\n",
                "    \n",
                "    start = t.find(\"[\")\n",
                "    end = t.rfind(\"]\")\n",
                "    if start != -1 and end != -1:\n",
                "        return t[start:end+1]\n",
                "    return t\n",
                "\n",
                "class MultiStepAgent:\n",
                "    def __init__(self):\n",
                "        pass\n",
                "\n",
                "    def run(self, query):\n",
                "        print(f\"[*] Routing: {query}\")\n",
                "        router_out_raw = generate(router_prompt(query))\n",
                "        router_out = extract_json(router_out_raw)\n",
                "        \n",
                "        try:\n",
                "            tool_calls = json.loads(router_out)\n",
                "        except Exception as e:\n",
                "            return f\"Router Error: Could not parse JSON.\\nRaw Output: {router_out_raw}\\nError: {e}\"\n",
                "\n",
                "        results = []\n",
                "        for call in tool_calls:\n",
                "            func_name = call.get(\"function\")\n",
                "            args = call.get(\"args\", {})\n",
                "            print(f\"[*] Executing: {func_name}({args})\")\n",
                "            \n",
                "            if func_name in TOOLS:\n",
                "                res = TOOLS[func_name](**args)\n",
                "                results.append({\"tool\": func_name, \"args\": args, \"result\": res})\n",
                "            else:\n",
                "                results.append({\"tool\": func_name, \"error\": \"Function not found\"})\n",
                "\n",
                "        print(f\"[*] Synthesizing final answer...\")\n",
                "        final_answer = generate(synthesize_prompt(query, results))\n",
                "        # Clean up any potential leftover thinking (robustness)\n",
                "        if \"</think>\" in final_answer:\n",
                "            final_answer = final_answer.split(\"</think>\")[-1].strip()\n",
                "        \n",
                "        return final_answer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Testing the Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================================\n",
                        "USER: Calculate 1024 times 4 and give me the latest Bitcoin price.\n",
                        "[*] Routing: Calculate 1024 times 4 and give me the latest Bitcoin price.\n",
                        "[*] Executing: arithmetic({'op': 'multiply', 'a': 1024, 'b': 4})\n",
                        "[*] Executing: get_price({'symbol': 'BTC-USD'})\n",
                        "[*] Synthesizing final answer...\n",
                        "AGENT: The product of 1024 and 4 is **4096**.  \n",
                        "The latest Bitcoin price is approximately **$88,259.20**.\n",
                        "\n",
                        "Let me know if you need further analysis!\n",
                        "==================================================\n",
                        "USER: What is the latest news for Nvidia and what is their current stock price?\n",
                        "[*] Routing: What is the latest news for Nvidia and what is their current stock price?\n",
                        "[*] Executing: get_news({'query': 'latest news for Nvidia'})\n",
                        "[*] Executing: get_price({'symbol': 'NVDA'})\n",
                        "[*] Synthesizing final answer...\n",
                        "AGENT: The latest news for Nvidia could not be retrieved due to an API key issue. However, the current stock price for NVDA is approximately $186.47. Let me know if you'd like further analysis or updates.\n",
                        "==================================================\n",
                        "USER: If I take the current Ethereum price and add 500, what is the result?\n",
                        "[*] Routing: If I take the current Ethereum price and add 500, what is the result?\n",
                        "[*] Executing: get_price({'symbol': 'ETH-USD'})\n",
                        "[*] Synthesizing final answer...\n",
                        "AGENT: The current Ethereum price is approximately $2,927.85. Adding 500 to this value results in a total of **$3,427.85**.\n",
                        "\n",
                        "Let me know if you need further calculations!\n"
                    ]
                }
            ],
            "source": [
                "agent = MultiStepAgent()\n",
                "\n",
                "queries = [\n",
                "    \"Calculate 1024 times 4 and give me the latest Bitcoin price.\",\n",
                "    \"What is the latest news for Nvidia and what is their current stock price?\",\n",
                "    \"If I take the current Ethereum price and add 500, what is the result?\"\n",
                "]\n",
                "\n",
                "for q in queries:\n",
                "    print(\"=\"*50)\n",
                "    print(f\"USER: {q}\")\n",
                "    response = agent.run(q)\n",
                "    print(f\"AGENT: {response}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
